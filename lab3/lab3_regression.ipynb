{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GyDBNNlbrdwl"
   },
   "source": [
    "# Импорты"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statistics import mode\n",
    "from multiprocessing import Pool\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "\n",
    "def entropy(y):\n",
    "    p = [len(y[y == k]) / len(y) for k in np.unique(y)]\n",
    "    return -np.dot(p, np.log2(p))\n",
    "\n",
    "\n",
    "def gini(y):\n",
    "    p = [len(y[y == k]) / len(y) for k in np.unique(y)]\n",
    "    return 1 - np.dot(p, p)\n",
    "\n",
    "\n",
    "def variance(y):\n",
    "    return np.var(y)\n",
    "\n",
    "\n",
    "def mad_median(y):\n",
    "    return np.mean(np.abs(y - np.median(y)))\n",
    "\n",
    "\n",
    "def regression_leaf(y):\n",
    "    return np.mean(y)\n",
    "\n",
    "\n",
    "def classification_leaf(y):\n",
    "    return mode(y)\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, feature_idx=0, threshold=0, labels=None, left=None, right=None):\n",
    "        self.feature_idx = feature_idx\n",
    "        self.threshold = threshold\n",
    "        self.labels = labels\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "\n",
    "class DecisionTree(BaseEstimator):\n",
    "    def __init__(self, max_depth=np.inf, min_samples_split=2, min_samples_leaf=1, criterion=\"variance\",\n",
    "                 leaf_func=\"regression_leaf\"):\n",
    "        params = {\n",
    "            \"max_depth\": max_depth,\n",
    "            \"min_samples_split\": min_samples_split,\n",
    "            \"min_samples_leaf\": min_samples_leaf,\n",
    "            \"criterion\": criterion,\n",
    "            \"leaf_func\": leaf_func\n",
    "        }\n",
    "\n",
    "        criteria_dict = {\n",
    "            \"variance\": variance,\n",
    "            \"mad_median\": mad_median,\n",
    "            \"gini\": gini,\n",
    "            \"entropy\": entropy\n",
    "        }\n",
    "\n",
    "        leaf_dict = {\n",
    "            \"regression_leaf\": regression_leaf,\n",
    "            \"classification_leaf\": classification_leaf\n",
    "        }\n",
    "\n",
    "        for param_name, param_value in params.items():\n",
    "            setattr(self, param_name, param_value)\n",
    "\n",
    "        super(DecisionTree, self).set_params(**params)\n",
    "        self._criterion_function = criteria_dict[criterion]\n",
    "        self._leaf_value = leaf_dict[leaf_func]\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.root = None\n",
    "        self.current_depth = 0\n",
    "\n",
    "    def _functional(self, x_train: pd.DataFrame, y: pd.Series, feature_idx: int, threshold):\n",
    "        mask = x_train.iloc[:, feature_idx] < threshold\n",
    "        n_obj = x_train.shape[0]\n",
    "        n_left = np.sum(mask)\n",
    "        n_right = n_obj - n_left\n",
    "        if n_left > 0 and n_right > 0:\n",
    "            return (\n",
    "                    self._criterion_function(y)\n",
    "                    - (n_left / n_obj) * self._criterion_function(y.loc[mask])\n",
    "                    - (n_right / n_obj) * self._criterion_function(y.loc[~mask])\n",
    "            )\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def _build_tree(self, x_train: pd.DataFrame, y: pd.Series, depth=1):\n",
    "        \"\"\"Train decision tree\"\"\"\n",
    "        max_functional = 0\n",
    "        best_feature_idx = None\n",
    "        best_threshold = None\n",
    "        n_samples, n_features = x_train.shape\n",
    "\n",
    "        if len(np.unique(y)) == 1:\n",
    "            return Node(labels=y)\n",
    "\n",
    "        best_mask = None\n",
    "        if depth < self.max_depth and n_samples >= self.min_samples_split and n_samples >= self.min_samples_leaf:\n",
    "            for feature_idx in range(n_features):\n",
    "                max_value = np.max(x_train.iloc[:, feature_idx])\n",
    "                min_value = np.min(x_train.iloc[:, feature_idx])\n",
    "                threshold_values = np.linspace(min_value, max_value, 5)\n",
    "                functional_values = [\n",
    "                    self._functional(x_train, y, feature_idx, threshold) for threshold in threshold_values\n",
    "                ]\n",
    "\n",
    "                best_threshold_idx = np.nanargmax(functional_values)\n",
    "\n",
    "                if functional_values[best_threshold_idx] > max_functional:\n",
    "                    max_functional = functional_values[best_threshold_idx]\n",
    "                    best_threshold = threshold_values[best_threshold_idx]\n",
    "                    best_feature_idx = feature_idx\n",
    "                    best_mask = x_train.iloc[:, feature_idx] < best_threshold\n",
    "\n",
    "        if best_feature_idx is not None and best_mask is not None:\n",
    "            return Node(\n",
    "                feature_idx=best_feature_idx,\n",
    "                threshold=best_threshold,\n",
    "                left=self._build_tree(x_train.loc[best_mask], y.loc[best_mask], depth + 1),\n",
    "                right=self._build_tree(x_train.loc[~best_mask, :], y.loc[~best_mask], depth + 1),\n",
    "            )\n",
    "        else:\n",
    "            self.current_depth = depth\n",
    "            return Node(labels=y)\n",
    "\n",
    "    def fit(self, x_train: pd.DataFrame, y: pd.Series):\n",
    "        \"\"\"Run training decision tree\"\"\"\n",
    "        self.root = self._build_tree(x_train, y)\n",
    "        self.max_depth = self.current_depth\n",
    "        return self\n",
    "\n",
    "    def _predict_object(self, x: pd.Series):\n",
    "        \"\"\"Prediction for one test object\"\"\"\n",
    "        node = self.root\n",
    "        while node.labels is None:\n",
    "            if x[node.feature_idx] < node.threshold:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        return self._leaf_value(node.labels)\n",
    "\n",
    "    def predict(self, x_test: pd.DataFrame) -> np.array:\n",
    "        \"\"\"Prediction for all test objects\"\"\"\n",
    "        results = np.array([self._predict_object(x_test.iloc[i]) for i in range(0, x_test.shape[0])])\n",
    "        return np.array(results)\n"
   ],
   "metadata": {
    "id": "8dwTzXp5EoBi"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-39Y7CBiENMM"
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "\n",
    "class GradientBoosting(BaseEstimator):\n",
    "    def __init__(self, n_estimators=10, learning_rate=0.01, max_depth=3, min_samples_split=5, criterion=\"variance\",\n",
    "                 leaf_func=\"regression_leaf\", random_state=17, loss_name=\"mse\"):\n",
    "\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.criterion = criterion\n",
    "        self.leaf_func = leaf_func\n",
    "        self.random_state = random_state\n",
    "        self.learning_rate = learning_rate\n",
    "        self.loss_name = loss_name\n",
    "        self.initialization = lambda y: np.mean(y) * np.ones([y.shape[0], 1])\n",
    "\n",
    "        if loss_name == \"mse\":\n",
    "            self.objective = self.mse\n",
    "            self.objective_grad = self.mse_grad\n",
    "\n",
    "        elif loss_name == \"rmsle\":\n",
    "            self.objective = self.rmsle\n",
    "            self.objective_grad = self.rmsle_grad\n",
    "\n",
    "        self.trees_ = []\n",
    "\n",
    "    @staticmethod\n",
    "    def mse(y, p):\n",
    "        return np.mean((y - p) ** 2)\n",
    "\n",
    "    @staticmethod\n",
    "    def mse_grad(y: np.array, p: np.array):\n",
    "        return 2 * (p - y) / y.shape[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def rmsle(y, p):\n",
    "        y = y.reshape([y.shape[0], 1])\n",
    "        p = p.reshape([p.shape[0], 1])\n",
    "        return np.mean(np.log((p + 1) / (y + 1)) ** 2) ** 0.5\n",
    "\n",
    "    def rmsle_grad(self, y, p):\n",
    "        y = y.reshape([y.shape[0], 1])\n",
    "        p = p.reshape([p.shape[0], 1])\n",
    "        return 1.0 / (y.shape[0] * (p + 1) * self.rmsle(y, p)) * np.log((p + 1) / (y + 1))\n",
    "\n",
    "    def fit(self, X: np.array, y: np.array):\n",
    "        b = self.initialization(y)\n",
    "        prediction = b.copy()\n",
    "\n",
    "        for t in tqdm(range(self.n_estimators)):\n",
    "            if t == 0:\n",
    "                resid = y\n",
    "            else:\n",
    "                resid = -self.objective_grad(y, prediction)\n",
    "\n",
    "            tree = DecisionTree(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                criterion=self.criterion,\n",
    "                leaf_func=self.leaf_func\n",
    "            )\n",
    "            tree.fit(X, pd.Series(resid))\n",
    "            b = tree.predict(X).reshape([X.shape[0], 1])\n",
    "            self.trees_.append(tree)\n",
    "            \"\"\"\n",
    "                вот тут можно найти такой learning_rate, что функция потерь от таргета и пресдказания*learning_rate\n",
    "                будет минимальна но я просто умножила его на предсказания и сложила с прошлыми предсказаниями\n",
    "                (обновляем текущее предсказание)\n",
    "            \"\"\"\n",
    "            prediction += self.learning_rate * b\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.ones([X.shape[0], 1])\n",
    "        for t in range(self.n_estimators):\n",
    "            predictions += self.learning_rate * self.trees_[t].predict(X).reshape([X.shape[0], 1])\n",
    "        return predictions"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T16:32:01.437580Z",
     "start_time": "2024-08-28T16:32:00.607472Z"
    },
    "id": "wpgkddE6riiH"
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import classification_report, roc_curve, r2_score, mean_squared_error"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ay8tK4l0Ii5w",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Функции для отрисовки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T16:36:46.358291Z",
     "start_time": "2024-08-28T16:36:46.355444Z"
    },
    "id": "9RjUiDb9IjAR"
   },
   "source": [
    "def show_histplot(data: pd.DataFrame, feature_name: str):\n",
    "    sns.histplot(data, kde=True, binwidth=0.1)\n",
    "    plt.xlabel(f'Значения {feature_name}')\n",
    "    plt.ylabel('Частота')\n",
    "    plt.title(f'Распределение {feature_name}')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_boxplot(df_column, column_name):\n",
    "    pd.DataFrame(df_column).boxplot(sym='o', whis=1.0, showmeans=True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_3d(param1: list[int], param2: list[int], result: list[int], name_param1: str, name_param2: str):\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes(projection ='3d')\n",
    "    ax.plot3D(param1, param2, result, 'green')\n",
    "    ax.set_title(f'Зависимость метрики R² от {name_param1} и {name_param2}')\n",
    "    plt.show()\n",
    "\n",
    "def get_2d(param1: list[int], result: list[int], name_param1: str):\n",
    "    plt.title(f'Зависимость метрики R² от {name_param1}')\n",
    "    plt.plot(param1, result)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "id": "ktdHLhUIENMO"
   },
   "source": [
    "# Всякие полезные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ncWdwr_QENMO"
   },
   "source": [
    "# Evaluation function\n",
    "def evaluation(model_name, y_test, y_pred_test, output=False):\n",
    "    r2_test = r2_score(y_test, y_pred_test)\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "\n",
    "    if output:\n",
    "        print(f'\\n{model_name} Evaluation:')\n",
    "        print(f'Test R²: {r2_test:.7f}')\n",
    "        print(f'Test RMSE: {rmse_test:.5f}')\n",
    "    return r2_test\n",
    "\n",
    "def output_metrics_classification(y_test: pd.Series, preds: pd.Series):\n",
    "    report = classification_report(y_test, preds, target_names=['Non-fail', 'Fail'])\n",
    "    print(report)\n",
    "\n",
    "def output_roc_auc(y_test: pd.Series, preds: pd.Series):\n",
    "    sns.set(font_scale=1.5)\n",
    "    sns.set_color_codes(\"muted\")\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, preds, pos_label=1)\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, lw=lw, label='ROC curve ')\n",
    "    plt.plot([0, 1], [0, 1])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curve')\n",
    "    plt.savefig(\"ROC.png\")\n",
    "    plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7XWT6eiG4tZ",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# EDA: Marketing campaign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T16:32:45.846924Z",
     "start_time": "2024-08-28T16:32:45.000169Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "GgW1NiH6G37J",
    "outputId": "9158f607-22ab-49a6-94a5-0e906e418c82"
   },
   "source": [
    "train_flood = pd.read_csv('train.csv')\n",
    "train_flood = train_flood.drop(['id'], axis=1)\n",
    "train_flood"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9_aLz6-OKrnM",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Распределение признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T16:33:18.742347Z",
     "start_time": "2024-08-28T16:32:51.117939Z"
    },
    "id": "KYv7qBR9Igm3"
   },
   "source": [
    "[show_histplot(train_flood[column], column) for column in train_flood.columns]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijxyclgYKyZi",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Тепловая карта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T16:36:58.953703Z",
     "start_time": "2024-08-28T16:36:57.769222Z"
    },
    "id": "C5Bzzz2iKz5p"
   },
   "source": [
    "sns.heatmap(train_flood.corr(), vmin=-1, vmax=1, center= 0, cmap= 'coolwarm')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "id": "jlQgNctyENMQ"
   },
   "source": [
    "## Выбросы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T16:37:20.906500Z",
     "start_time": "2024-08-28T16:37:06.658741Z"
    },
    "id": "DSHVx14qTlSu"
   },
   "source": [
    "[get_boxplot(train_flood[column], column) for column in train_flood.columns]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nw3SxHvMfZZe"
   },
   "source": [
    "#### Смотрим на выбросы в процентах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T16:34:16.002861Z",
     "start_time": "2024-08-28T16:34:15.569329Z"
    },
    "id": "zMlXhXx4fZnA"
   },
   "source": [
    "def find_outliers(df):\n",
    "    outliers = {}\n",
    "    for col in df.columns:\n",
    "        v = df[col]\n",
    "        q1 = v.quantile(0.25)\n",
    "        q3 = v.quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - 1.5 * iqr\n",
    "        upper_bound = q3 + 1.5 * iqr\n",
    "        outliers_count = ((v < lower_bound) | (v > upper_bound)).sum()\n",
    "        perc = outliers_count * 100.0 / len(df)\n",
    "        outliers[col] = (perc, outliers_count)\n",
    "        print(f\"Column {col} outliers = {perc:.2f}%\")\n",
    "\n",
    "    return outliers\n",
    "\n",
    "outliers = find_outliers(train_flood)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C3n33maEfo9g"
   },
   "source": [
    "**Итог по выбросам:**\n",
    "- как будто бы до пизды на выбросы, тем более не везде они выбросы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ie1BrHbUnMB1",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T16:34:30.593959Z",
     "start_time": "2024-08-28T16:34:28.910057Z"
    },
    "id": "gI1U0l6mnQjp"
   },
   "source": [
    "train_flood['mean'] = train_flood[train_flood.columns].mean(axis=1)\n",
    "train_flood['std'] = train_flood[train_flood.columns].std(axis=1)\n",
    "train_flood['max'] = train_flood[train_flood.columns].max(axis=1)\n",
    "train_flood['median'] = train_flood[train_flood.columns].median(axis=1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jREVrUPhENMQ"
   },
   "source": [
    "*ИТОГ*:\n",
    "\n",
    "Я решила ввести новые признаки, потому что в древовидных моделях (Дерево решений, случайный лес, градиентный бустинг) нет естественного способа агрегирования информации по многим объектам одновременно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "id": "uzxSyoBhENMQ"
   },
   "source": [
    "## Смотрим на важность признаков и на зависимость"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MLVglXjUENMQ"
   },
   "source": [
    "X = train_flood\n",
    "y = X['FloodProbability']\n",
    "X = X.drop('FloodProbability', axis=1, inplace=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HwUtjms6ENMQ",
    "outputId": "05b6903f-f709-4603-d17a-81eecb2c8fac"
   },
   "source": [
    "def make_mi_scores(X, y, discrete_features):\n",
    "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "def plot_mi_scores(scores):\n",
    "    scores = scores.sort_values(ascending=True)\n",
    "    width = np.arange(len(scores))\n",
    "    ticks = list(scores.index)\n",
    "    plt.barh(width, scores)\n",
    "    plt.yticks(width, ticks)\n",
    "    plt.title(\"Mutual Information Scores\")\n",
    "\n",
    "discrete_features = X.dtypes == int\n",
    "mi_scores = make_mi_scores(X, y, discrete_features)\n",
    "mi_scores[::3]\n",
    "plt.figure(dpi=100, figsize=(8, 5))\n",
    "plot_mi_scores(mi_scores)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "id": "aYAAj5OuENMR"
   },
   "source": [
    "# Разделение на train/test/valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ScpsJcJ3ENMR"
   },
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42, stratify=y_test)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9NJ4soyw6Hr",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Обучение/тест - Дерево решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "id": "tGS89J44ENMR"
   },
   "source": [
    "## Моя реализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QukT5bvvENMR",
    "outputId": "25ab1112-120d-4a58-a6bd-3da1a0d85f5d"
   },
   "source": [
    "min_samples_split = [4, 10, 15]\n",
    "min_samples_leaf = [3, 9, 14]\n",
    "best_tree = None\n",
    "best_metric = -1\n",
    "\n",
    "for leaf in min_samples_leaf:\n",
    "    for slpit in min_samples_split:\n",
    "        tree = DecisionTree(max_depth=100, min_samples_split=slpit, min_samples_leaf=leaf, criterion=\"variance\", leaf_func=\"regression_leaf\")\n",
    "        tree.fit(X_train, y_train)\n",
    "        predictions = tree.predict(X_test)\n",
    "\n",
    "        r2 = evaluation(\"Decision Tree\", y_test, predictions, output=False)\n",
    "        print(f'Обучили дерево с параметрами min_samples_leaf={leaf}, min_samples_split={slpit}, depth={tree.max_depth}: R² = {r2}')\n",
    "        if best_metric < r2:\n",
    "            best_metric = r2\n",
    "            best_tree = tree"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iTpsvYVdENMR"
   },
   "source": [
    "*ИТОГ*:\n",
    "\n",
    "Есть некое наитие, что дерево с максимальной глубиной равной 15 переобучилось."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WKl5J7vJENMR",
    "outputId": "4681ea9a-276e-42e5-d44f-09ae4d89220b"
   },
   "source": [
    "max_depth = range(5,12)\n",
    "metric_values = []\n",
    "for depth in max_depth:\n",
    "    tree = DecisionTree(max_depth=depth, min_samples_split=5, criterion=\"variance\", leaf_func=\"regression_leaf\")\n",
    "    tree.fit(X_train, y_train)\n",
    "    predictions = tree.predict(X_test)\n",
    "\n",
    "    r2 = evaluation(\"Decision Tree\", y_test, predictions, output=False)\n",
    "    print(f'Обучили дерево с параметром max_depth={depth}: R² = {r2}')\n",
    "    metric_values.append(r2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z33stJ6GENMR",
    "outputId": "fc2e6e76-fc8c-40fb-a40b-eb03172a1cf2"
   },
   "source": [
    "get_2d(max_depth, metric_values, \"max_depth\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "id": "dV4yzMZbENMR"
   },
   "source": [
    "### Проверяем, есть ли переобучение\n",
    "\n",
    "Давайте протестируем на тестовой выборке деревья с наилучшими результатами.\n",
    "\n",
    "P.S.\n",
    "Тут я использую X_valid, y_valid, но на самом деле из-за того, как определила валидационную и тестовую выборку, без разници, какую использовать для валидации, а какую для теста. Мне просто лень исправлять и перезапускать ячейки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UZwvQHQbENMR",
    "outputId": "0488506d-2899-4a25-bf1a-b0d6c5ef7e1f"
   },
   "source": [
    "tree = DecisionTree(max_depth=15, min_samples_split=15, criterion=\"variance\", leaf_func=\"regression_leaf\")\n",
    "tree.fit(X_train, y_train)\n",
    "predictions = tree.predict(X_val)\n",
    "\n",
    "r2 = evaluation(\"Decision Tree\", y_val, predictions, output=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5ZOSwA_ENMR"
   },
   "source": [
    "**ИТОГ:**\n",
    "\n",
    "Тестирование показало, что всё ок, но я бы всё не брала дерево с такой глубиной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "id": "G0kw129pENMS"
   },
   "source": [
    "## Библиотичная реализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sIPEBndjENMS",
    "outputId": "b2d2b357-c826-4c91-997d-1f9f0e22ae0b"
   },
   "source": [
    "X = train_flood\n",
    "y = X['FloodProbability']\n",
    "X = X.drop('FloodProbability', axis=1, inplace=False)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "lib_tree = DecisionTreeRegressor()\n",
    "param_grid = {\n",
    "    'max_depth': [5, 7, 11],\n",
    "    'min_samples_split': [4, 6, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(lib_tree, param_grid, cv=4, scoring='r2', verbose=True)\n",
    "grid_search.fit(X, y)\n",
    "print(\"Лучшие параметры:\", grid_search.best_params_)\n",
    "print(\"Лучший счет:\", grid_search.best_score_)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7TB0yudoENMS"
   },
   "source": [
    "**ИТОГ:**\n",
    "\n",
    "Моя реализация дала лучшие результаты при тех же параметрах, но думаю, что на самом деле это не совсем так. В реализации sklearn используется такая вещь как Minimal Cost-Complexity Pruning, которое предотвращает переобучение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "id": "5MeYM5O1ENMS"
   },
   "source": [
    "# Обучение/тест - Случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "id": "B4gXtbQaENMX"
   },
   "source": [
    "## Моя реализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "id": "N-T5tFrPENMX"
   },
   "source": [
    "### Найдем лучшие параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iH66DO87ENMX",
    "outputId": "e8914553-60f6-41b7-e113-783d20a4525c"
   },
   "source": [
    "max_depth = [5, 7, 11]\n",
    "n_estimators = [5, 15, 25]\n",
    "\n",
    "best_metric = -1\n",
    "best_forest = None\n",
    "\n",
    "for depth in max_depth:\n",
    "    for estimators in n_estimators:\n",
    "        forest = RandomForest(max_depth=depth, min_samples_split=10, min_samples_leaf=11, criterion=\"variance\", leaf_func = \"regression_leaf\", N=estimators)\n",
    "        forest.fit(X_train, y_train)\n",
    "        preds_forest = forest.predict(X_test)\n",
    "        r2 = evaluation(\"Random Forest\", y_test, preds_forest, output=False)\n",
    "\n",
    "        if r2 > best_metric:\n",
    "            best_forest = forest\n",
    "            best_metric = r2"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AtVh7ebdENMY",
    "outputId": "b5dcd490-aef3-4c84-c337-093345a62532"
   },
   "source": [
    "print(f\"Параметры лучшего леса: количество деревьев={best_forest.N}, глубина={best_forest.max_depth}, r2={best_metric}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "id": "wutUTgezENMY"
   },
   "source": [
    "### Посмотрим теперь на зависимость метрики от количества деревьев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BpsN3UrLENMY",
    "outputId": "b84ce856-814c-4ee0-8143-f3617ece3d56"
   },
   "source": [
    "n_estimators = range(10,25,2)\n",
    "metrics = []\n",
    "\n",
    "for estimators in n_estimators:\n",
    "    forest = RandomForest(max_depth=11, min_samples_split=10, min_samples_leaf=11, criterion=\"variance\", leaf_func = \"regression_leaf\", N=estimators)\n",
    "    forest.fit(X_train, y_train)\n",
    "    preds_forest = forest.predict(X_test)\n",
    "    r2 = evaluation(\"Random Forest\", y_test, preds_forest, output=False)\n",
    "    metrics.append(r2)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fxN2pfj7ENMY",
    "outputId": "a298d38d-6a76-43b1-8a99-4efc15a15c27"
   },
   "source": [
    "get_2d(n_estimators, metrics, \"n_estimators\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "id": "sBtzi0WMENMY"
   },
   "source": [
    "## Библиотечная реализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "id": "rMwCPYnjENMY"
   },
   "source": [
    "### Найдем лучшие параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z2POeyVVENMY",
    "outputId": "b072d727-1229-4e98-cba0-f9efd97c568a"
   },
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "lib_forest = RandomForestRegressor()\n",
    "param_grid = {\n",
    "    'max_depth': [5, 7, 11],\n",
    "    'n_estimators': [5, 10, 15]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(lib_forest, param_grid, cv=4, scoring='r2', verbose=True)\n",
    "grid_search.fit(X, y)\n",
    "print(\"Лучшие параметры:\", grid_search.best_params_)\n",
    "print(\"Лучший счет:\", grid_search.best_score_)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VlfG-R2iENMY"
   },
   "source": [
    "### Посмотрим теперь на зависимость метрики от количества деревьев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pIo3DV7WENMY",
    "outputId": "19f327b4-657e-4e8b-fc2b-0936756f99aa"
   },
   "source": [
    "lib_forest = RandomForestRegressor()\n",
    "param_grid = {\n",
    "    'n_estimators': range(10, 25, 2)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(lib_forest, param_grid, cv=2, scoring='r2', verbose=True)\n",
    "grid_search.fit(X, y)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d7x-dPEvENMZ",
    "outputId": "5a0f8a8e-0c34-47f3-dfd9-b60aca944d95"
   },
   "source": [
    "get_2d(n_estimators, grid_search.cv_results_['mean_test_score'], \"n_estimators\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JwLFUHNUENMZ"
   },
   "source": [
    "# Обучение/тест - Градиентный бустинг"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Моя реализация"
   ],
   "metadata": {
    "id": "6lg7UsECK21t"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Подберем лучшие параметры"
   ],
   "metadata": {
    "id": "V-EiYUreK6Xe"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3bSHjzzRENMZ",
    "outputId": "9fb83db4-f52c-4aaf-d0c0-4fc26b1102d6"
   },
   "source": [
    "max_depth = [5, 7, 11]\n",
    "n_estimators = [5, 15, 25]\n",
    "\n",
    "best_metric = -1\n",
    "best_forest = None\n",
    "\n",
    "for depth in max_depth:\n",
    "    for estimators in n_estimators:\n",
    "        boosting = GradientBoosting()\n",
    "        boosting.fit(X_train, y_train)\n",
    "        preds_boosting = forest.predict(X_test)\n",
    "        r2 = evaluation(\"Gradient boosting\", y_test, preds_boosting, output=False)\n",
    "\n",
    "        if r2 > best_metric:\n",
    "            best_forest = forest\n",
    "            best_metric = r2"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"Параметры лучшего леса: количество деревьев={best_forest.N}, глубина={best_forest.max_depth}, r2={best_metric}\")"
   ],
   "metadata": {
    "id": "x8NAwMtBKthH"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Посмотрим на зависимость между количеством деревьев и метрикой"
   ],
   "metadata": {
    "id": "W7g1s41xLAHP"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qvf3iqeMENMZ"
   },
   "source": [
    "n_estimators = range(10,25,2)\n",
    "metrics = []\n",
    "\n",
    "for estimators in n_estimators:\n",
    "    boosting = GradientBoosting()\n",
    "    boosting.fit(X_train, y_train)\n",
    "    preds_boosting = forest.predict(X_test)\n",
    "    r2 = evaluation(\"Gradient boosting\", y_test, preds_boosting, output=False)\n",
    "    metrics.append(r2)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "GyDBNNlbrdwl",
    "ay8tK4l0Ii5w",
    "ktdHLhUIENMO",
    "I7XWT6eiG4tZ",
    "9_aLz6-OKrnM",
    "ijxyclgYKyZi",
    "jlQgNctyENMQ",
    "Ie1BrHbUnMB1",
    "uzxSyoBhENMQ",
    "aYAAj5OuENMR",
    "M9NJ4soyw6Hr",
    "tGS89J44ENMR",
    "G0kw129pENMS",
    "5MeYM5O1ENMS",
    "B4gXtbQaENMX",
    "N-T5tFrPENMX",
    "wutUTgezENMY",
    "sBtzi0WMENMY",
    "JwLFUHNUENMZ",
    "V-EiYUreK6Xe",
    "W7g1s41xLAHP"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
